\chapter{Stand van zaken}
\label{ch:stand-van-zaken}

% Tip: Begin elk hoofdstuk met een paragraaf inleiding die beschrijft hoe
% dit hoofdstuk past binnen het geheel van de bachelorproef. Geef in het
% bijzonder aan wat de link is met het vorige en volgende hoofdstuk.

% Pas na deze inleidende paragraaf komt de eerste sectiehoofding.

There are a lot of different ways to secure a network. It is impossible to test and talk about all of them. So in this thesis we focus on the techniques that are viable to us. These are techniques that can be applied in our situation and that are within our knowledge. In this segment we'll take a closer look at a thesis on which the idea for this scripture was based on. After that some research and explanation about different approaches one can take will be given. For each method there are pros and cons, and these will be made clear here. Later on these methods will be tested as well.
\section{Cheating at Digital Exams: Vulnerabilities and Countermeasures}
This thesis was written by Aleksander Heintz for the Norwegian University of Science and Technology. In his work he focusses on ways to circumvent the current implented system at the school so that students can cheat at digital examinations.
\subsection{Environment}
The Norwegian University of Science and Technology (NTNU) currently uses `Safe Exam Browser' in combination with `Inspera Assessment` on private devices. Students are required to install these to be able to take a digital exam
To be able to explain how these both work, we first have to explain what a Learning Management System (LMS) is.
\subsection{Learning Management System}
A learning Management System is a system that supports an organisation in it's capability to give employees or students the opportunity to learn and study. It's part of the eLearning Industry. It enables the organization to host online training courses.For companys it becomes very easy for employees to keep learning without having to plan physical hours sitting in rooms and hiring teachers. In schools it can be used to host course materials and such. There are multiple deployment options when using LMS. \\
It can be cloud-based (SaaS). This enables organizations to have a wide reach with their training resourches. This deployment requires very little time to deploy and practically no IT knowledge. It's good for organizations who want a quick start with online learning.\\
Secondly there is Self-Hosted LMS's. These require software to be downloaded. Chamillo (the system we use in our College) is A Self-Hosted LMS (SOURCE). These often required payed updates however and some IT knowledge to be able to deploy. Self-Hosted LMS's do allow the organization a big amount of customization and control.\\
The third option is a Desktop Application. This is an LMS application that is downloaded locally on each desktop of all the users. It's easier to deploy than a Self-Hosted service but you still have a little bit more control than you have with SaaS systems.\\
And lastly there are Mobile Applications. These are pretty self-explanatory. They are quite the same as the one mentioned above but they are installed on a cellphone. So they can be accessed everywhere where you take your phone with you.\\
As one can expect there are different licensing types as well when using LMS. You can have a paid license. This requires a monthly or yearly cost but ensures support and stability. When you run a company that has no IT'er on site (which in these days might be pretty rare) this option would be best for you. However if you'd rather spent less money and already have an IT'er on site you can go for open source or a free license. In open source applications you can change the code to your desire and modify the application. This requires quite some knowledge however so an IT'er is a must have. A lot of open source projects have active online communicties which can always help of course. But this doesn't change the fact that programming knowledge is required. Then lastly, the free license is comparable with an open source project but it might be a little bit less modifiable.\\
With a paid license you can have different pricing models as well, most of the times this will be one of the following: Licensing, Subscription or Freemium. Each has it's disadvantages and opportunities. Licensing is most used in big organizations, subscriptions in smaller organizations who want to minimize cost but offer LMS to all employees. And freemium in organizations where only the basic features are required to start.\\

But why would an organization choose to use a LMS? There are multiple advantages to using an LMS. First of all it's an easy way to store your learning data. In case of a school environment for examaple, there is no need to print a thousand syllabi, these can all be made available on the used platform. And as a bonus most LMS systems provide a encryption service, so these files are protected. An other big advantage is the possibility to monitor the users. There is access to statistics about the use of the LMS services. This way a lot of information is available about all courses and certain actions can be taken based on this information.
But possibly the most important factor is the simple fact that it makes learning easier. It makes it so that everybody can learn everywhere. A lot of restrictions that you have when just using pen and paper are gone when using LMS. And this reduces cost and frustration among users.\\

So in conclusion, a learning management system is a system that allows the organization to make learning available to all employees/students in a very accessible and digital way.

\subsection{Safe Exam Browser}
As the name suggests, Safe Exam Browser (SEB)  is a browser like firefox,chrome, etc. but configured specifically for setting up an environment for conducting digital examinations. Which makes it more than just a normal browser. With the SEB browser also comes a tool for configuration and authentication. Which both are used for setting up the environment.\\

SEB is an open source project and is free to use. SEB's ancestor was a project called `WinKeyOx` which was an application developed by StefanSchneider of the University of Giessen(SOURCE FAQ). He banded together with people of ETH Zurich \textit{(Eidgenössische Technische Hochschule Zürich)} and in 2009 part of the project became open source under MPL( Mozilla Public License). Any use of the source code has to be according to the rules set in that License. Currently it is still `owned' by ETH Zurich. But as the websites mentions, SEB is not owned or ran by anyone as it is a open source project.
The fact that this application is open source has it's advantages and disadvantages just like all other open source projects have. A big advantage of SEB is that it is free (not all open source projects are but it is common among them). The downside of course is that specific support might be an issue. There is a very active community surrounding SEB but specific problems might not be important enough for this community to solve etc. So it's very usefull when using SEB to have an IT on staff.\\

SEB is installed locally on the devices of the students. It creates a secure environment on which students can partake in digital examinations while blocking as many ways to cheat as possible. SEB is connected to a LMS via an active internet connection. In our case this would of course be Chamillo (if possible) but in this thesis they used Inspera Assessment. Inspera Assessment even has examinations specially designed for them to be conducted using SEB.
SEB consists out of three main components: The kiosk application, The SEB Browser and the LMS. The kiosk app is the part the controls the computer while taking the examination. It ensures that hotkeys are blocked, that other applications can't interfere, etc. 
The browser is the User Interface for the students. This browser is specially designed to hide certain features that an ordinary browser would have (like an address bar etc.). Moodle and ILIAS are two Learning management systems that have code for integration with this browser. It makes it so that examinations on those two can only be taken when using the SEB. It also allow for a lot stricter ways of controlling the environment. \\

\subsection{Inspera Assessment}
Inspera Assessment is used in combination with SEB at NTNU. It is a website that provides services for making and conducting examinations. One could say that it is a little part of a LMS. In our case, Chamillo has a build in feature to conduct examinations. These can be multiple choice exams but don't have to be.  Inspera does this, but more extensive than the build in function in Chamillo. Inspera is a Norwegian company and as far as I can tell is based on the Norwegian education system. As Inspera Assessment is not important to the rest of this thesis we will not discuss it any further. More information can be found on their website. ( SOURCE WEBSITE) 

\subsection{Findings}
Aleksander Heints tried a lot of different ways of breaking the system and being able to cheat while using SEB. It is worth mentioning however that a lot of these methods require a big amount of knowledge and would not easily be reproduced. It is important to remember that the subjects are not experienced computer scientists but are still students. An other important note is that these findings are now all solved and are no longer possible ways to cheat.\\

\begin{itemize}
\item Inserting your own code into the code of SEB was one of the first things mentioned in the thesis. This however turned out to be impossible (or very difficult) to do on windows machines because these use Certification that do not come from the Global store of Certifications  but rather used its own. On a macOS however, it did work because the browsers on macOS use the global certification store. He did this using a reverse proxy server that he developed himself. It did however, enable him to add a custom search button inside of the browser window that seemed like it was part of it. So a student could make his own web server, place files on there that would help him to make the examination and then access that server by adding it to the browser by injecting code.
\item Accessing the LMS outside the safe environment or in other words, making Inspera believe that the user is using SEB while in fact he is uses a browser of his choice. This was the second exploit tested. For this exploit he had to figure out the secret key used by SEB (which is not that hard to do) and start the reverse proxy server so that he could trick Inspera into believing that the browser sending requests to their server was in fact SEB. The conclusion was that this was an other viable way to cheat at an examination.
\item Modifying SEB is the last on the list of exploits he tried. The first thing mentioned is the key that gets generated by Safe Exam Browser to see if you are actually running SEB. This is done by a single method in C\# and simply checks the location of the file being ran. So it's pretty easy to change this code into making it a static route. So that the key always returns a correct value. It's also possible to create a new C\# .NET program that depends on the code of SEB. This way, all public methods are available to the new project you created and you can easily create your own program that allows you to do whatever you like, while being able to trick SEB into thinking that you are actually using the correct browser for making the exam.
\end{itemize}

So we can conclude that there are quite some exploits that were found. But as mentioned before, these exploits aren't so easily found. They probably aren't that hard for someone who is fluent in c\# programming and knows quite something about authentication on the web. But in the case of our school I believe this is not knowledge that most students have. In addition to that, the program is open source and keeps getting updates. So as students figure out ways to bypass the system, the system will get updated and prevent those methods.
A system that is one hundred percent secure will probably never exist, but in our scenario, SEB seems te be getting pretty close.

\section{Router ACL configuration}
Even though the previous section seems to answer all our questions. It's worth exploring more. The first thing when thinking about limiting internet access that pops up in most peoples mind is probably configuring your router.  It's a logical decision to make as your router is the device that takes care of all the packages leaving and entering your network. This will also be the first method we'll test and take a closer look at. The term that should ring a bell is an ACL (Access Control List). If you talk about filtering data using a router the most common used method is using ACLs. There may be other ways out there (Vyos has a built in firewall for example) but these are mostly just ACLs covered in a layer of handy commands. So in this section we will focus on what ACL's are and how we could use them.
In our test environment we use a Vyos router. The reason why this decision was made is explained later in the appropriate section.
\subsection{What is an ACL}
You can see an ACL as a list of allowed visitors to a party combined with a banned list of people. So if you would go to a party where the bouncer is a router with an ACL multiple things can happen. You can get denied access to the party because you are not on the list. You can get denied because you are on the banned list. You can get allowed access because you are on the allowed list or finally you can get access because you are not mentioned anywhere.
In reality the visitors are packets being sent to the router. Either from inside to the outside or the other way around. Both ways can be filtered. Multiple ACLs can be configured on one router. Most of the time, each of them has it's own function. The list itself is a literal list of commands which each have some definition as to what they are allowing and on what interface. These lines are called Acces control Entries (ACEs). When traffic tries to get through the router it is always compared to each ACE in sequential order. (Meaning that the first ACE on the ACL will get checked first and the last will be checked lastly.) If for instance the first ACE of an ACL will match with all the packets, and for instance allow all of them, none of the other ACE will ever be checked and applied.The last line of an ACL always is a deny all. So if an ACL is applied to a interface, and a packet does not match with any of the listed ACE's, it will get dropped. \\
It is important to realize that filtering data is not the only use of ACLs. They have a very broad range of functionalities. But these are not of importance to the scope of this thesis. You can for instance prioritize certain traffic over other. It can lower usage of the internet for certain services, and so on.
While it is true that without an ACL configured on a router, a router does not filter anything coming through. It is not the case that configuring an ACL on a router should be considered as a good enough protection of your network. You should always use multiple ways of protecting your network and not just rely on this one option.
\subsection{Transmission control protocol}
To give a better understanding of what an ACL does it is useful to know how devices communicate with each other. This section won't go into much detail and will be a brief explanation. A full explanation of this protocol could probably fill a whole thesis on its own.
The first thing TCP does is split up data that it receives from an application into different packages. These are the packages mentioned earlier, the ones that an ACL filters.
The second thing it does is establish a connection between a server and your application. If you want to send an email, this would be a mail server. When visiting a website this would be a web server, etc. Both sides need to agree to the connection for it to be established. This is where a router can step in and refuse to establish a connection resulting in this transmission of packets being denied.
The packets mentioned earlier contain a lot of different so called segments. Each segment holds information about the package being sent. It is based on these segments that an ACL can filter out certain packages being sent or received.
\subsection{Filtering Data}
A router/ACL can filter on multiple things. But it is all based (as mentioned above) on the content of the package.The segment always identify what the purpose is of a certain package. One segment for instance holds the source IP-address and the destination IP-address. This way an ACL can check if this IP is on a list of blocked or allowed ip addresses and can act accordingly. So if you want a certain user to not be able to visit a specific website, you could just add the IP of that site to an ACL and tell it to block it. Then every package that comes through with that IP in the destination or source segment will be denied and dropped as a result.\\
An other way is to check the TCP/UDP source and destination port. These are the segments that define the purpose of the package. For instance, if a package is meant for file transferring (FTP) the segment will be set to use port the TCP port 20/21. If we don't want any user to use TCP, we can configure the ACL to block all packets that contain TCP 20/21 as source our destination port. Some other important ports that are good to know are:
\begin{itemize}
\item SSH: TCP 22
\item Telnet: TCP 23
\item DNS: TCP/UDP 53
\item DHCP: UDP: 67/68
\item HTTP: TCP 80
\item HTTPS: TCP 443
\end{itemize}
 These might not mean to you much right now, but they will be important once we try to use ACLs to filter data going through our router.
 \subsection{Different kinds of ACLs}
 There are two big kinds of ACLs. You have the inbound ACL and the outbound ACL. Both have all the features described above but the difference is as to where they are placed. On which location this ACL will inspect the packages and decide if they can go through or not.
 The positioning of an ACL is extremely important. It might almost be as important as the actual content of it. As an ACL that is misplaced is completely useless and might even do harm to your network.
 An inbound ACL will check packages before they get routed. This kind is mainly used when you want to filter a package based upon the source.
 An outbound ACL check a packet after it's being routed. This is mainly used when you want to filter based upon the destination.
 An other distinction that is being made when talking about ACL's is standard and extended ACL's. Who can both be named and numbered ACL's. Named ACL's are simply ACL's that have been given a name. This means that an other approach will be taken when configuring them as well. Numbered ACL's are given a number (standard: 1-99, 1300-1999 ; extended: 100-199, 2000-2699). Generally in bigger networks one will use named ACL to make clear what the purpose is of each. But on smaller networks where not a lot of ACL's are present, numbered ones may be used as well, for quick configuration. a standard ACL only filters based on IP addresses, nothing more. An extended ACL can filter on multiple factors like: Protocol type, source/destination IPv4 address, source/destination TCP/UDP ports, optional protocol information. To check IP addresses, wildcard masks are used.
 \subsubsection{wildcard mask}
 Ip addresses in ACL's are compared with a wildcard mask. A wildcard mask is very similar to a subnet mask. But in reverse. All the bits that stay the same will have the value 0, while the bits that change will have value 1. So will a wildcard equal to \textit{0.0.255.255}  always check the two first numbers of an IPv4 address. For instance \textit{192.168.10.0} will be matched to  \textit{192.168.0.0}. So a wildcard mask of \textit{0.0.0.0} will match with the exact IP address, while \textit{255.255.255.255} will match with all the IP addresses.  Further information on this subject is not on it's place here, because when reading this paper a small understanding of networking was assumed, and understanding this is part of that.
 \subsection{Configuration of ACL's}
 \subsubsection{Placement of ACL's}
 Before one should start configuring ACL's they should decide where to place it. An ACL is always placed on a certain interface on some device in the network. If for instance you want to limit access to a certain server from all networks, you should place an ACL on the last interface that goes to that server. In that ACL you then place the allowed networks that may reach the server. The alternative would be to place an ACL for each network on each of its network devices, which would clearly require a lot more work and mean more opportunity for errors to occur. When you want to block a specific network's access to a certain server, it's easier to place an ACL on the first router that is passed. Because otherwise, when placed right in front of the server all traffic that goes trough will be checked with that ACL, which is not needed as we only want to block one network. Plus the overhead will be a lot bigger than if we place it as an inbound ACL on the nearest router.
 \subsubsection{Standard IPv4 ACL's}
 The following example is the simple configuration of a \textit{numbered standard ACL} when using Cisco IOS. Do notice that it may different from OS, but the premise always stays the same.
\begin{cisco}[title=Numbered standard ACL]
Router(config)#  access-list 3 deny host 192.168.10.10
Router(config)#  access-list 3 permit 192.168.10.0 0.0.0.255
Router(config)#  int s0/1/0
Router(config-if)# ip access-group 3 out
\end{cisco}
In this snippet the numbered ACL 3 is configured. The first entered line will deny a package which has the IP \textit{192.168.10.10} in it's source IP segment. The second line will then allow every packet which originates from the \textit{192.168.10.0} network. Remember that every other packet that does not match both these statements is dropped because of the implicit deny at the end of every ACL. The reason that host \textit{192.168.10.10} won't be allowed trough because of the second line is because every ACL is ran from top to bottom and the process is stopped from the moment a match is found. So with this host, the package will be dropped before ever being compared to the second ACE.
The following statement just switching us to the configuration mode for the Serial 0/1/0 interface. There we use the ip access-group command to assign a certain ACL to an interface. In this case it's ACL 3 which functions as an outbound ACL (checking traffic that leaves through this interface).
Creating a named standard ACL has the same logic behind the process. The difference of course being that the ACL has a name instead of a number:
\begin{cisco}[title=Named standard ACL]
Router(config)#  ip access-list standard NAMED
Router(config-std-nacl)#  10 deny host 192.168.10.10
Router(config-std-nacl)#  20 permit 192.168.10.0 0.0.0.255
Router(config-std-nacl)#  exit
Router(config)#  int s0/1/0
Router(config-if)#  ip access-group NAMED out
\end{cisco}
This fragment of configuration does the same as the one shown earlier. Except it uses a named ACL. The biggest advantage of the named ACL (as mentioned before) is the fact that in big networks it keeps a clear view of what the function is of each ACL.
The numbers are a way to specify the place of the ACE in the ACL. If here you would switch those numbers, the permit ACE would be put in front of the deny host ACE resulting in all traffic from \textit{192.168.10.0} being allowed. These are optional but can be useful when one needs to adjust an ACL without having to rewrite it as a whole.
\subsubsection{Extended IPv4 ACL's}
Extended ACL's are a lot more precise than standard ACL. When you want to allow a network to send mails to a certain other network, but disable FTP, you'll have a hard time doing this with standard ACL's. While with extended ACL's this is achieved pretty quick. The syntax is a lot alike to configuring standard ACL's. For instance you have named and numbered ones, but the only difference is the way we configure it and the fact that one has a name and the other has a number. In the following fragment an example of configuring a extended IPv4 ACL on cisco IOS.
\begin{cisco}[title=Numbered extended ACL]
Router(config)#  access-list 180 deny tcp 192.168.10.0 0.0.0.255 192.168.12.0 0.0.0.255 eq ftp
Router(config)#  access-list 180 deny tcp 192.168.10.0 0.0.0.255 192.168.12.0 0.0.0.255 eq ftp-data
Router(config)#  access-list 180 permit ip any any
Router(config)#  interface s0/0/0
Router(config-if)#  ip access-group 180 in
\end {cisco}
This creates extended ACL 180 who causes all packages from the \textit{192.168.10.0} network to the \textit{192.168.12.0} to be dropped if these packages contain the port number in the destination port segment of the package equal to the ftp or the ftp-data part. If this is not the case, all traffic is allowed through because of the third ACE.\\

A lot more can be said about ACL's and configuring them, but knowing this much will be enough to understand what we do when trying to protect our network by using ACL's.
\subsection{ACL's on Vyos}
Vyos does not use ACL's, and seeing as vyos is being used in the test environment it's not a bad idea to shortly explain how it works on this particular OS. It will be clear that there are a lot of similarities. The syntax may be different but the idea behind package filtering on a router will always be the same.\\
Vyos uses a firewall for package filtering. A certain rule can be set on more than just an interface. It can be set on a group of ports/addresses and networks as well as on a zone.
A zone is a collection of different networks put together. This only occurs in complex networks. But does not really impact the way the ACL works, just the impact the ACl itself has on the network.\\
A group is a collection of ports,networks or IP addresses. So image if you wanted to use the same ACL on cisco IOS on different interfaces, here you would add all those interfaces to a group and then write the rules for that group. This might be confusing to understand but a quick example code will clear things up.
\begin{cisco}[title=Creating firewall groups]
# Creating a group for certain networks to which you want to apply the same rules
set firewall group network-group NET-INSIDE network 192.168.0.0/24
set firewall group network-group NET-INSIDE network 192.168.1.0/24
# Creating a group for certain ports to which you want to apply the same rules
set firewall group port-group PORT-TCP-SERVER1 port 80
set firewall group port-group PORT-TCP-SERVER1 port 443
set firewall group port-group PORT-TCP-SERVER1 port 5000-5010
\end {cisco}
So if a packet of one of the two networks (\textit{192.168.0.0/24} \& \textit{192.168.1.0/24}) wants to pass the router, it will be checked with all the rules that are given to the NET-INSIDE group. Or if a packet witch contains one of the ports specified want to pass, the same will happen but then for the PORT-TCP-SERVER group. So the groups already decide multiple things that in Cisco are placed within the ACL or have to be configured manually. It decides which packets should match these rules based on the port or IP. To assign a certain set of rules to a group one simply has to create a rule set and specify within.
\begin{cisco}[title=Configuring a rule set]
set firewall name TEST default-action drop
set firewall name TEST rule 100 action reject
set firewall name TEST rule 100 destination group port-group PORT-TCP-SERVER
set firewall name TEST rule 100 source group network-group NET-INSIDE
\end{cisco}
It might seem intimidating at first, but with some practice a lot comes clear. The main thing to understand is that everything is put into groups. The things that we want to prevent access from and the things we want to prevent access to. This includes ports and hosts/networks. Once all of our groups are created, we create rules to connect these groups with each other and so build a system that filters packages.
\section{ Domain name system}
\subsection{A short introduction to DNS}
Just like we use names to communicate with people, computers use IP-Addresses. But because IP-Addresses are a bit hard to remember for us mere humans, we assign hostnames (\textit{Hogent.be}) to those IP-Addresses. The translation of these hostnames to IP-Addresses (and the other way around) is one of the main tasks of a DNS-server. A commonly used software for performing this task is the Berkeley Internet Name Domain (BIND) which is unix based and which is the one we'll be using in our test environment. The DNS protocol itself uses UDP and port 53. Normally the process of requesting a translation goes as follows:
\begin{itemize}
\item A client extracts the URL from the application that the user is using to navigate to a certain website.
\item The URL is queried on to the DNS server
\item The DNS server receives the query and searches in its storage for a translation
\item The DNS server sends a reply with the corresponding IP-Address to the client (if this is present, otherwise it will notify the client that it does not exist or ask an other DNS server)
\item The client receives the IP-Address and initiates a TCP connection based on that IP.
\end{itemize}
A DNS server does more than just translate though. Some of the other functionalities one has are:
\begin{itemize}
\item Host aliasing, replacing difficult hostnames with more comprehensive ones.
\item Mail server aliasing, basically the same as done with hostnames but then in the case of email addresses (hotmail.com instead of relay1.west-flanders.hostmail.com)
\item Load distribution, if a website has a lot of traffic, it might be usefull to have this site hosted on multiple webservers. The DNS will then equally give out the IP of each webserver to balance the load on each one.
\end{itemize}
There are four kinds of DNS servers, each has its own function in a network.\\
First off there are the Root DNS servers. There are only 13 in the internet. These are located all over the world are actually consist out of multiple servers clustered together. These root servers know the location of the Top-level domain servers and will send out this information. These are part of the backbone of the internet. Without these a DNS request would get lost pretty easily and fast. These however, are not important to us. 
The second kind are the top-level domain(TLD) servers. These are the .com, .org, .be, ... servers. They are in the hierarchical  one level below the root DNS Servers. They are responsible for all the propagation and such around the domain servers mentioned. These are still way to big for us to matter.\\
Thirdly, there are the Authoritative DNS servers. This is the first kind that will have importance to us. Each publicly available server must have some DNS records stored somewhere so that people can reach it. This so that their names are mapped to their corresponding IP-Address. An authoritative DNS server is the server that holds these records. A company can have it's own authoritative server or can choose to host their records somewhere else (against payment). Often there are primary and secondary DNS servers. This is nothing more than a backup in case something goes wrong.
The second type that has meaning to us, is the local DNS server. When a host connects to the enterprise network (so no home networks) there will be a local DHCP and DNS server. The DHCP server will provide the host with an IP-Address and the address of the local DNS server. The local DNS will receive the queries from the client for DNS requests and forward these queries into the DNS server hierarchy. It is in this part of the process that we can interfere. If we tell our local DNS server that he is not to forward any queries except for those that we allow, we will limit internet access by not allowing our users to reach certain websites.\\
A lot more can be said about DNS servers, more information can be found in multiple places. For this thesis [SOURCE DNS] was used. To keep this introduction short, different kinds of records,queries,etc. will not be explained here.
\subsection{Whitelisting vs. Blacklisting}
Blacklisting means to put a certain unwanted website/IP in a list on your DNS server. In this list you place the hostnames of these websites and connect them with a bogus IP. This way, if the local DNS gets a request to translate the website in question, it will return an incorrect IP-Address and the connection will fail. This technique is used a lot to filter out spam in mail-servers. Where known spam addresses are added to the list and if an email arrives from one of those domains, an action will be taken against it. In the case of this thesis we want to do the same but with unwanted websites. If a student is trying to visit a website that is known to us, we want it to be unreachable. And blacklisting seems like one way to achieve this.\\
Whitelisting is the opposite of blacklisting. It is a list of addresses that you want to be translated correctly. This can be done by forwarding them to an authoritative name server or by manually entering the correct IP-Address into the list so that a translations can be done locally. This would mean that only those addresses on the list would get translated and all the others will get blocked.\\
In our scenario it sounds a lot more interesting to test out whitelisting. As for now it seems like blacklisting seems to let a lot of room for students to find websites that are not on the list and just use those. While when you only allow certain websites it will already be a lot harder to find a way around that.The precise way of how to do this will be touched upon later in this thesis. When we try this method in our test environment.
\subsection{Dnsmasq}
Dnsmasq is free software that is installed on most Linuq distributions. It functions as a DNS forwarder for small networks. It is interesting to us because it allows a user to input certain translations into the /etc/hosts file on the linux system. This is originally meant to be able to add translations for local machines which do not need to be present on public DNS servers. But it also allows users to add addresses to that list that they want to be translated incorrectly. In our setup we'll be using DNSMasq to try and filter packets in our network.
\subsection{BIND}
BIND is an open source software for setting up a DNS server on unix systems. It is the software that we will use on a CentOS machine in our test environment. BIND consists out of 3 parts. The first being a Domain Name Resolver. This means that the server serves as a proxy. It will send requests for translations to the correct servers and forward the responses to the client that requested it. But it can also function as an authoritative name server which, as explained before, holds its own translation for its own network. In this case it will respond to requests from resolvers and clients with the information that it holds about its domain. The third part is Tools. BIND offers a wide variety of tools used for diagnostic and operational purposes. 
\section{Firewall}
\subsection{Role of a firewall}
\subsection{Using a firewall to block websites}
\subsection{PFSense}
\section{Deep Packet Filtering}
\subsection{Explanation}
\subsection{Issues}
% SOURCE DNS: Computer Networking A top-down approach fifth edition, James F. Kurose, Keith W. Ross
% source ACLs: Routing and Switching Essentials van cisco, chapter 9: Access Control Lists

% source VYOS: https://wiki.vyos.net/wiki/User_Guide

% source safe exam browser : https://www.youtube.com/watch?v=PlBA2qo9fZs
% SOURCE FAQ: https://www.safeexambrowser.org/consortium/faq.html

% source Inspera: http://www.inspera.com/
%SOURCE WEBSITE: http://www.inspera.com/
% source LMS: https://elearningindustry.com/what-is-an-lms-learning-management-system-basic-functions-features
% source LMS: https://en.wikipedia.org/wiki/Learning_management_system

% SOURCE CHAMILLO SELF HOSTED: https://elearningindustry.com/directory/software-categories/learning-management-systems/deployment/hosted